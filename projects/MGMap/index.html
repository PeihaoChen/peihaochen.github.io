
<html lang="en" class="mutli-granularity-map_scut"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Required meta tags -->
    <title>Weakly-Supervised Multi-Granularity Map Learning for Vision-and-Language Navigation</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="keywords" content="video, sound, audio, deep learning, computer vision, machine learning">
    <meta name="description" content="n">

    <!-- Bootstrap CSS -->
   <link rel="stylesheet" href="./mutli-granularity-map_files/bootstrap.min.css">
    <link rel="stylesheet" href="./mutli-granularity-map_files/bootstrap-theme.min.css">

    <script type="text/javascript" async="" src="./mutli-granularity-map_files/analytics.js.下载"></script><script type="text/javascript" async="" src="./mutli-granularity-map_files/analytics.js(1).下载"></script><script type="text/javascript" async="" src="./mutli-granularity-map_files/analytics.js(2).下载"></script><script type="text/javascript" async="" src="./mutli-granularity-map_files/analytics.js(2).下载"></script>
    <script src="./mutli-granularity-map_files/popper.min.js.下载"></script>
    <script src="./mutli-granularity-map_files/bootstrap.min.js.下载"></script>
    <script async="" src="./mutli-granularity-map_files/js"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments) };
        gtag('js', new Date());
        gtag('config', 'UA-81724582-4');
    </script>

    <style>
        body {
            font-size: 16px
        }
        .navbar-fixed-top {
            min-height: 60px;
        }

        .navbar-nav>li>a {
            padding-top: 0px;
            padding-bottom: 0px;
            line-height: 60px;
            font-size: 22px;
            color:gray;
        }
        
        .navbar-nav>li>a:active {
            color:white;
        }
        
        .navbar-nav>li>a:hover {
            color:white;
            -webkit-tap-highlight-color: rgba(0,0,0,0);
            -webkit-tap-highlight-color:transparent;
            outline:none;
            background:none;
            text-decoration: none;
        }
        

    </style>
    <!-- Custom styles for this template -->
    <link href="./mutli-granularity-map_files/jumbotron.css" rel="stylesheet">
</head>



<body data-gr-c-s-loaded="true" style="cursor: url(&quot;chrome-extension://jlgkpaicikihijadgifklkbpdajbkhjo/image/cursors/009.png&quot;), default;" data-new-gr-c-s-check-loaded="14.1028.0" data-gr-ext-installed="" class="vsc-initialized">
    <nav class="navbar-fixed-top" style="background-color: rgb(44, 42, 42)">
        <a class="navbar-brand" href="./active-camera.html#" style="font-size: 25px; color:white">WS-MGMap</a>

        <div class="collapse navbar-collapse" id="navbarsExampleDefault">
            <ul class="nav navbar-nav mr-auto">
                <li><a href="./active-camera.html#Video" style="font-size: 20px">Video</a></li>
                <li><a href="./active-camera.html#Paper" style="font-size: 20px">Paper</a></li>
                <li><a href="./active-camera.html#Code" style="font-size: 20px">Code</a></li>
               <li><a href="./active-camera.html#More" style="font-size: 20px">More</a></li>
            </ul>
        </div>
    </nav>


    <main role="main">
        <div class="container" style="padding-top: 80px; font-size: 20px">
            <div align="center">
                <h1 class="text-center" aligh="center">
                    Weakly-Supervised Multi-Granularity Map Learning for Vision-and-Language Navigation
                </h1><br>

                <a href="https://peihaochen.github.io/"><b>Peihao Chen</b></a> &nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://peihaochen.github.io/"><b>Dongyu Ji</b></a> &nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://peihaochen.github.io/"><b>Kunyang Lin</b></a> &nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://peihaochen.github.io/"><b>Runhao Zeng</b></a> &nbsp;&nbsp;&nbsp;&nbsp;
                <br>
                <a href="https://peihaochen.github.io/"><b>Thomas H.Li</b></a> &nbsp;&nbsp;&nbsp;&nbsp;
                <a href="https://peihaochen.github.io/"><b>Mingkui Tan</b></a> &nbsp;&nbsp;&nbsp;&nbsp;
                <a href="http://people.csail.mit.edu/ganchuang/"><b>Chuang Gan</b></a> &nbsp;&nbsp;&nbsp;&nbsp;

                <br><br>
            </div>
        </div>

        <br><br>


        <div class="container">
            <h3 id="RFSleep" style="padding-top: 80px; margin-top: -80px;">Abstract:</h3>
            <hr>
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
                    
                We address a practical yet challenging problem of training robot agents to navigate in an environment following a path described by some language instructions. The instructions often contain descriptions of objects in the environment. To achieve accurate and efficient navigation, it is critical to build a map that accurately represents both spatial location and the semantic information of the environment objects. However, enabling a robot to build a map that well represents the environment is extremely challenging as the environment often involves diverse objects with various attributes. In this paper, we propose a multi-granularity map, which contains both object fine-grained details (\eg, color, texture) and semantic classes, to represent objects more comprehensively. Moreover, we propose a weakly-supervised auxiliary task, which requires the agent to localize instruction-relevant objects on the map. Through this task, the agent not only learns to localize the instruction-relevant objects for navigation but also is encouraged to learn a better map representation that reveals object information. We then feed the learned map and instruction to a waypoint predictor to determine the next navigation goal. Experimental results show our method outperforms the state-of-the-art by 4.0% and 4.6% w.r.t. success rate both in seen and unseen environments, respectively on VLN-CE dataset. The code is available at https://github.com/PeihaoChen/WS-MGMap.
                </div>
                <div style="margin-top: 280px">
                <div class="col-md-10 col-md-offset-1">
                </div>
            </div>
        </div>
        <!-- <br><br> -->


        <div class="container">
            <h3 id="Video" style="padding-top: 80px; margin-top: -80px;">Video:</h3>
            <hr>
            <div class="col-md-1"></div>
            <div class="col-md-10">
                <div class="embed-responsive embed-responsive-16by9">
                    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/kuWVx9wKbLA" frameborder="0" allowfullscreen=""></iframe>
                    <!-- <iframe class="embed-responsive-item" src="./mutli-granularity-map_files/5uMT8Mk-JlE.html" frameborder="0" allowfullscreen=""></iframe> -->
                </div>
            </div>
        </div><br><br>

        


        <div class="container">
            <h3 id="Paper" style="padding-top: 80px; margin-top: -80px;">Paper:</h3>
            <hr>
            <div class="row">
                <div class="col-md-9">
                    <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/f959b05dd74ba8a735276c3df4ae8b71-Abstract-Conference.html"><b>
                        Weakly-Supervised Multi-Granularity Map Learning for Vision-and-Language Navigation
                        </b><br></a>
                        Peihao Chen, Dongyu Ji, Kunyang Lin, Runhao Zeng, Thomas H.Li, Mingkui Tan, Chuang Gan  <br>
                        <i> NeurIPS 2022 (<span style="color:red;"><b>Spotlight</b></span>)</i><br>
                    <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/f959b05dd74ba8a735276c3df4ae8b71-Paper-Conference.pdf">[PDF]<br></a>
                </div>
            </div>
        </div><br><br>


        <!-- -->
       <div class="container">
            <h3 id="Code" style="padding-top: 80px; margin-top: -80px;">Code</h3>
            <hr>
            <div class="row">
                <div class="col-md-9">
                     <a href="https://github.com/PeihaoChen/WS-MGMap" class="download-link">Dataset and Codebase</a> 
            </div>
            </div>
        </div><br><br>
       
 <div class="container">
            <h3 id="More" style="padding-top: 80px; margin-top: -80px;">Related Publications</h3>
            <hr>

            <div class="row">
                <div class="col-md-9">
                    <b><a target="_blank" href="./active-camera.html">
                            <font color="black">Learning Active Camera for Multi Object Navigation</font>
                        </a></b><br>
                   
                    <a href="https://peihaochen.github.io/"><b>Peihao Chen</b></a>,
                    <a href="https://peihaochen.github.io/"><b>Dongyu Ji</b></a>,
                    <a href="https://peihaochen.github.io/"><b>Kunyang Lin</b></a>,
                    <a href="https://peihaochen.github.io/"><b>Weiwen Hu</b></a>,
                    <a href="https://peihaochen.github.io/"><b>Wenbing Huang</b></a>,
                    <a href="https://peihaochen.github.io/"><b>Thomas H.Li</b></a>,
                    <a href="https://peihaochen.github.io/"><b>Mingkui Tan</b></a>, and
                    <a href="http://people.csail.mit.edu/ganchuang/"><b>Chuang Gan</b></a>,
    
                    <br>
                    <i> NeurIPS 2022</i><br>
                </div>
            </div>

            
            

        </div><br><br>

    </div></main>




<grammarly-desktop-integration data-grammarly-shadow-root="true"><template shadowrootmode="open"><style>
  div.grammarly-desktop-integration {
    position: absolute;
    width: 1px;
    height: 1px;
    padding: 0;
    margin: -1px;
    overflow: hidden;
    clip: rect(0, 0, 0, 0);
    white-space: nowrap;
    border: 0;
    -moz-user-select: none;
    -webkit-user-select: none;
    -ms-user-select:none;
    user-select:none;
  }

  div.grammarly-desktop-integration:before {
    content: attr(data-content);
  }
</style><div aria-label="grammarly-integration" role="group" tabindex="-1" class="grammarly-desktop-integration" data-content="{&quot;mode&quot;:&quot;full&quot;,&quot;isActive&quot;:true,&quot;isUserDisabled&quot;:false}"></div></template></grammarly-desktop-integration></body></html>